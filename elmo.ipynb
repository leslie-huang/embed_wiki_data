{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "\n",
    "from allennlp.commands.elmo import ElmoEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
    "weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [00:00<00:00, 84866.08B/s]\n",
      "100%|██████████| 374434792/374434792 [08:56<00:00, 698392.55B/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'elmo_representations': [tensor([[[-0.0471, -0.3260, -0.6423,  ..., -0.0660,  0.3173,  0.3172],\n",
       "           [ 0.6056, -0.1005,  0.1127,  ...,  0.5817,  0.3201,  0.7672],\n",
       "           [-0.4786, -0.4143, -0.6049,  ..., -0.0803,  0.0361,  0.1128]],\n",
       "  \n",
       "          [[ 0.2603, -0.4437,  0.2726,  ..., -0.0830, -0.1522, -0.1361],\n",
       "           [-0.7772, -0.4294, -0.2651,  ..., -0.0803,  0.0361,  0.1128],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  tensor([[[-0.0471, -0.3260, -0.6423,  ..., -0.0660,  0.3173,  0.3172],\n",
       "           [ 0.6056, -0.1005,  0.1127,  ...,  0.5817,  0.3201,  0.7672],\n",
       "           [-0.4786, -0.4143, -0.6049,  ..., -0.0803,  0.0361,  0.1128]],\n",
       "  \n",
       "          [[ 0.2603, -0.4437,  0.2726,  ..., -0.0830, -0.1522, -0.1361],\n",
       "           [-0.7772, -0.4294, -0.2651,  ..., -0.0803,  0.0361,  0.1128],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "         grad_fn=<CopySlices>)],\n",
       " 'mask': tensor([[1, 1, 1],\n",
       "         [1, 1, 0]])}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code from this tutorial: https://github.com/allenai/allennlp/blob/master/tutorials/how_to/elmo.md\n",
    "\n",
    "# Compute two different representation for each token.\n",
    "# Each representation is a linear weighted combination for the\n",
    "# 3 layers in ELMo (i.e., charcnn, the outputs of the two BiLSTM))\n",
    "elmo = Elmo(options_file, weight_file, 2, dropout=0)\n",
    "\n",
    "# use batch_to_ids to convert sentences to character ids\n",
    "sentences = [['Test', 'sheep', '.'], ['Another', '.']]\n",
    "character_ids = batch_to_ids(sentences)\n",
    "\n",
    "embeddings = elmo(character_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[-0.0471, -0.3260, -0.6423,  ..., -0.0660,  0.3173,  0.3172],\n",
       "          [ 0.6056, -0.1005,  0.1127,  ...,  0.5817,  0.3201,  0.7672],\n",
       "          [-0.4786, -0.4143, -0.6049,  ..., -0.0803,  0.0361,  0.1128]],\n",
       " \n",
       "         [[ 0.2603, -0.4437,  0.2726,  ..., -0.0830, -0.1522, -0.1361],\n",
       "          [-0.7772, -0.4294, -0.2651,  ..., -0.0803,  0.0361,  0.1128],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "        grad_fn=<CopySlices>),\n",
       " tensor([[[-0.0471, -0.3260, -0.6423,  ..., -0.0660,  0.3173,  0.3172],\n",
       "          [ 0.6056, -0.1005,  0.1127,  ...,  0.5817,  0.3201,  0.7672],\n",
       "          [-0.4786, -0.4143, -0.6049,  ..., -0.0803,  0.0361,  0.1128]],\n",
       " \n",
       "         [[ 0.2603, -0.4437,  0.2726,  ..., -0.0830, -0.1522, -0.1361],\n",
       "          [-0.7772, -0.4294, -0.2651,  ..., -0.0803,  0.0361,  0.1128],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "        grad_fn=<CopySlices>)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeddings['elmo_representations'] is length two list of tensors.\n",
    "# Each element contains one layer of ELMo representations with shape\n",
    "# (2, 3, 1024).\n",
    "#   2    - the batch size\n",
    "#   3    - the sequence length of the batch\n",
    "#   1024 - the length of each ELMo vector\n",
    "\n",
    "embeddings[\"elmo_representations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other example\n",
    "\n",
    "ee = ElmoEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3816778   0.2601955  -0.27387285 ...  0.21414772 -0.31411317\n",
      " -0.46676502]\n",
      "[ 0.47849342 -0.40329033 -0.27019072 ...  0.47313985  0.06390661\n",
      " -0.24718228]\n",
      "[ 0.49110138 -0.40165097  0.26552275 ... -0.39823037  0.06944599\n",
      "  0.5665358 ]\n"
     ]
    }
   ],
   "source": [
    "# The ElmoEmbedder class returns three vectors for each word, each vector corresponding to a layer in the \n",
    "# ELMo LSTM output. The first layer corresponds to the context insensitive token representation, followed \n",
    "# by the two LSTM layers. See the ELMo paper or follow up work at EMNLP 2018 for a description of what types \n",
    "# of information is captured in each layer.\n",
    "\n",
    "for i in range(3):\n",
    "    print(ee.embed_sentence(['i', 'am', 'flying', 'to', 'new', 'york'])[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.8134119 , -0.63056827,  0.5182505 , ..., -0.70603675,\n",
       "          0.56682426,  0.01298006],\n",
       "        [-0.5621832 , -0.27352428, -0.07766137, ...,  1.0250176 ,\n",
       "         -0.20382307, -0.15430188],\n",
       "        [-0.88715035, -0.20039932, -1.060133  , ..., -0.2655458 ,\n",
       "          0.21145992,  0.19772941]],\n",
       "\n",
       "       [[ 0.25827685, -0.19399653, -1.1400886 , ...,  0.09824269,\n",
       "         -0.18094376,  0.0101051 ],\n",
       "        [ 1.0442259 , -0.48662874, -0.19318259, ...,  0.39772868,\n",
       "          0.4329107 ,  0.5663998 ],\n",
       "        [-0.36431175, -0.6467032 ,  0.11072873, ..., -0.02805123,\n",
       "         -0.01774108,  0.05961663]],\n",
       "\n",
       "       [[ 0.19796309, -0.46005875, -1.8209531 , ...,  0.4071253 ,\n",
       "          0.54252553,  0.922896  ],\n",
       "        [ 1.4947687 ,  0.2033867 ,  0.20443833, ...,  0.35850075,\n",
       "          0.73835933,  1.8798531 ],\n",
       "        [-0.26518375, -0.66888607, -1.253718  , ..., -0.00874215,\n",
       "         -0.08153988,  0.07605419]]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee.embed_sentence([\"Test\", \"sheep\", \".\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
